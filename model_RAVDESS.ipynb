{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Other  \n",
    "import librosa\n",
    "import librosa.display\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob \n",
    "import os\n",
    "import pickle\n",
    "import IPython.display as ipd  # To play sound in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Actor_01', 'Actor_02', 'Actor_03', 'Actor_04', 'Actor_05']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio = \"F:/audio_speech_actors_01-24/\"\n",
    "actor_folders = os.listdir(audio) #list files in audio directory\n",
    "actor_folders.sort() \n",
    "actor_folders[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = []\n",
    "gender = []\n",
    "actor = []\n",
    "file_path = []\n",
    "for i in actor_folders:\n",
    "    filename = os.listdir(audio + i) #in actor folder\n",
    "    for f in filename: #in files of actor folder\n",
    "        part = f.split('.')[0].split('-')\n",
    "        emotion.append(int(part[2]))\n",
    "        actor.append(int(part[6]))\n",
    "        bg = int(part[6])\n",
    "        if bg%2 == 0:\n",
    "            bg = \"female\"\n",
    "        else:\n",
    "            bg = \"male\"\n",
    "        gender.append(bg)\n",
    "        file_path.append(audio + i + '/' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>emotion</th>\n",
       "      <th>actor</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>F:/audio_speech_actors_01-24/Actor_01/03-01-01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>F:/audio_speech_actors_01-24/Actor_01/03-01-01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>F:/audio_speech_actors_01-24/Actor_01/03-01-01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>F:/audio_speech_actors_01-24/Actor_01/03-01-01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>calm</td>\n",
       "      <td>1</td>\n",
       "      <td>F:/audio_speech_actors_01-24/Actor_01/03-01-02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>female</td>\n",
       "      <td>surprise</td>\n",
       "      <td>24</td>\n",
       "      <td>F:/audio_speech_actors_01-24/Actor_24/03-01-08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>female</td>\n",
       "      <td>surprise</td>\n",
       "      <td>24</td>\n",
       "      <td>F:/audio_speech_actors_01-24/Actor_24/03-01-08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>female</td>\n",
       "      <td>surprise</td>\n",
       "      <td>24</td>\n",
       "      <td>F:/audio_speech_actors_01-24/Actor_24/03-01-08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>female</td>\n",
       "      <td>surprise</td>\n",
       "      <td>24</td>\n",
       "      <td>F:/audio_speech_actors_01-24/Actor_24/03-01-08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>female</td>\n",
       "      <td>surprise</td>\n",
       "      <td>24</td>\n",
       "      <td>F:/audio_speech_actors_01-24/Actor_24/03-01-08...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender   emotion  actor  \\\n",
       "0       male   neutral      1   \n",
       "1       male   neutral      1   \n",
       "2       male   neutral      1   \n",
       "3       male   neutral      1   \n",
       "4       male      calm      1   \n",
       "...      ...       ...    ...   \n",
       "1435  female  surprise     24   \n",
       "1436  female  surprise     24   \n",
       "1437  female  surprise     24   \n",
       "1438  female  surprise     24   \n",
       "1439  female  surprise     24   \n",
       "\n",
       "                                                   path  \n",
       "0     F:/audio_speech_actors_01-24/Actor_01/03-01-01...  \n",
       "1     F:/audio_speech_actors_01-24/Actor_01/03-01-01...  \n",
       "2     F:/audio_speech_actors_01-24/Actor_01/03-01-01...  \n",
       "3     F:/audio_speech_actors_01-24/Actor_01/03-01-01...  \n",
       "4     F:/audio_speech_actors_01-24/Actor_01/03-01-02...  \n",
       "...                                                 ...  \n",
       "1435  F:/audio_speech_actors_01-24/Actor_24/03-01-08...  \n",
       "1436  F:/audio_speech_actors_01-24/Actor_24/03-01-08...  \n",
       "1437  F:/audio_speech_actors_01-24/Actor_24/03-01-08...  \n",
       "1438  F:/audio_speech_actors_01-24/Actor_24/03-01-08...  \n",
       "1439  F:/audio_speech_actors_01-24/Actor_24/03-01-08...  \n",
       "\n",
       "[1440 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_df = pd.DataFrame(emotion)\n",
    "audio_df = audio_df.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\n",
    "audio_df = pd.concat([pd.DataFrame(gender),audio_df,pd.DataFrame(actor)],axis=1)\n",
    "audio_df.columns = ['gender','emotion','actor']\n",
    "audio_df = pd.concat([audio_df,pd.DataFrame(file_path, columns = ['path'])],axis=1)\n",
    "audio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-700.3989, 58.63021, -3.025852, 16.040241, 4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-695.55786, 59.240154, -5.3727765, 19.776367,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-694.00433, 61.49651, -3.2627435, 16.971298, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-687.51337, 59.44154, -0.703714, 16.645708, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-729.98016, 66.51589, -0.9419841, 19.070974, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature\n",
       "0  [-700.3989, 58.63021, -3.025852, 16.040241, 4....\n",
       "1  [-695.55786, 59.240154, -5.3727765, 19.776367,...\n",
       "2  [-694.00433, 61.49651, -3.2627435, 16.971298, ...\n",
       "3  [-687.51337, 59.44154, -0.703714, 16.645708, 3...\n",
       "4  [-729.98016, 66.51589, -0.9419841, 19.070974, ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['feature'])\n",
    "\n",
    "# loop feature extraction over the entire dataset\n",
    "counter=0\n",
    "for index,path in enumerate(audio_df.path):\n",
    "    X, sample_rate = librosa.load(path, res_type='kaiser_fast')\n",
    "    sample_rate = np.array(sample_rate)\n",
    " \n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X,sr=sample_rate,n_mfcc=40).T,axis=0)\n",
    "    df.loc[counter] = [mfccs]\n",
    "    counter=counter+1   \n",
    "\n",
    "# Checkthe first few recordings\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>emotion</th>\n",
       "      <th>actor</th>\n",
       "      <th>path</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>F:/audio_speech_actors_01-24/Actor_01/03-01-01...</td>\n",
       "      <td>-700.398926</td>\n",
       "      <td>58.630211</td>\n",
       "      <td>-3.025852</td>\n",
       "      <td>16.040241</td>\n",
       "      <td>4.248529</td>\n",
       "      <td>3.869935</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.411359</td>\n",
       "      <td>-2.769772</td>\n",
       "      <td>-2.042009</td>\n",
       "      <td>-2.522663</td>\n",
       "      <td>-2.507448</td>\n",
       "      <td>-2.250499</td>\n",
       "      <td>-0.381507</td>\n",
       "      <td>-2.481059</td>\n",
       "      <td>-2.791023</td>\n",
       "      <td>-2.244865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>F:/audio_speech_actors_01-24/Actor_01/03-01-01...</td>\n",
       "      <td>-695.557861</td>\n",
       "      <td>59.240154</td>\n",
       "      <td>-5.372777</td>\n",
       "      <td>19.776367</td>\n",
       "      <td>5.200387</td>\n",
       "      <td>3.324630</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.055913</td>\n",
       "      <td>-3.102514</td>\n",
       "      <td>-1.697880</td>\n",
       "      <td>-2.922661</td>\n",
       "      <td>-2.544465</td>\n",
       "      <td>-1.289832</td>\n",
       "      <td>-0.797254</td>\n",
       "      <td>-3.586074</td>\n",
       "      <td>-2.706395</td>\n",
       "      <td>-2.812933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>F:/audio_speech_actors_01-24/Actor_01/03-01-01...</td>\n",
       "      <td>-694.004333</td>\n",
       "      <td>61.496510</td>\n",
       "      <td>-3.262743</td>\n",
       "      <td>16.971298</td>\n",
       "      <td>2.142968</td>\n",
       "      <td>4.266798</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.382858</td>\n",
       "      <td>-2.590943</td>\n",
       "      <td>-1.929074</td>\n",
       "      <td>-2.390322</td>\n",
       "      <td>-2.269381</td>\n",
       "      <td>-2.486079</td>\n",
       "      <td>-0.589257</td>\n",
       "      <td>-3.248326</td>\n",
       "      <td>-2.979813</td>\n",
       "      <td>-2.769281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>F:/audio_speech_actors_01-24/Actor_01/03-01-01...</td>\n",
       "      <td>-687.513367</td>\n",
       "      <td>59.441540</td>\n",
       "      <td>-0.703714</td>\n",
       "      <td>16.645708</td>\n",
       "      <td>3.730826</td>\n",
       "      <td>6.181194</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.024173</td>\n",
       "      <td>-2.586190</td>\n",
       "      <td>-2.420421</td>\n",
       "      <td>-3.243219</td>\n",
       "      <td>-2.762588</td>\n",
       "      <td>-1.960003</td>\n",
       "      <td>-0.453890</td>\n",
       "      <td>-2.976706</td>\n",
       "      <td>-2.914763</td>\n",
       "      <td>-3.909605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>calm</td>\n",
       "      <td>1</td>\n",
       "      <td>F:/audio_speech_actors_01-24/Actor_01/03-01-02...</td>\n",
       "      <td>-729.980164</td>\n",
       "      <td>66.515892</td>\n",
       "      <td>-0.941984</td>\n",
       "      <td>19.070974</td>\n",
       "      <td>4.297080</td>\n",
       "      <td>5.635082</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.519869</td>\n",
       "      <td>-1.797158</td>\n",
       "      <td>-1.296814</td>\n",
       "      <td>-3.051891</td>\n",
       "      <td>-1.131349</td>\n",
       "      <td>-1.063672</td>\n",
       "      <td>-1.141021</td>\n",
       "      <td>-2.373389</td>\n",
       "      <td>-3.204345</td>\n",
       "      <td>-3.363193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender  emotion  actor                                               path  \\\n",
       "0   male  neutral      1  F:/audio_speech_actors_01-24/Actor_01/03-01-01...   \n",
       "1   male  neutral      1  F:/audio_speech_actors_01-24/Actor_01/03-01-01...   \n",
       "2   male  neutral      1  F:/audio_speech_actors_01-24/Actor_01/03-01-01...   \n",
       "3   male  neutral      1  F:/audio_speech_actors_01-24/Actor_01/03-01-01...   \n",
       "4   male     calm      1  F:/audio_speech_actors_01-24/Actor_01/03-01-02...   \n",
       "\n",
       "            0          1         2          3         4         5  ...  \\\n",
       "0 -700.398926  58.630211 -3.025852  16.040241  4.248529  3.869935  ...   \n",
       "1 -695.557861  59.240154 -5.372777  19.776367  5.200387  3.324630  ...   \n",
       "2 -694.004333  61.496510 -3.262743  16.971298  2.142968  4.266798  ...   \n",
       "3 -687.513367  59.441540 -0.703714  16.645708  3.730826  6.181194  ...   \n",
       "4 -729.980164  66.515892 -0.941984  19.070974  4.297080  5.635082  ...   \n",
       "\n",
       "         30        31        32        33        34        35        36  \\\n",
       "0 -1.411359 -2.769772 -2.042009 -2.522663 -2.507448 -2.250499 -0.381507   \n",
       "1 -1.055913 -3.102514 -1.697880 -2.922661 -2.544465 -1.289832 -0.797254   \n",
       "2 -1.382858 -2.590943 -1.929074 -2.390322 -2.269381 -2.486079 -0.589257   \n",
       "3 -2.024173 -2.586190 -2.420421 -3.243219 -2.762588 -1.960003 -0.453890   \n",
       "4 -1.519869 -1.797158 -1.296814 -3.051891 -1.131349 -1.063672 -1.141021   \n",
       "\n",
       "         37        38        39  \n",
       "0 -2.481059 -2.791023 -2.244865  \n",
       "1 -3.586074 -2.706395 -2.812933  \n",
       "2 -3.248326 -2.979813 -2.769281  \n",
       "3 -2.976706 -2.914763 -3.909605  \n",
       "4 -2.373389 -3.204345 -3.363193  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([audio_df,pd.DataFrame(df['feature'].values.tolist())],axis=1)\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 44)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>emotion</th>\n",
       "      <th>actor</th>\n",
       "      <th>path</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>F:/audio_speech_actors_01-24/Actor_01/03-01-01...</td>\n",
       "      <td>-700.398926</td>\n",
       "      <td>58.630211</td>\n",
       "      <td>-3.025852</td>\n",
       "      <td>16.040241</td>\n",
       "      <td>4.248529</td>\n",
       "      <td>3.869935</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.411359</td>\n",
       "      <td>-2.769772</td>\n",
       "      <td>-2.042009</td>\n",
       "      <td>-2.522663</td>\n",
       "      <td>-2.507448</td>\n",
       "      <td>-2.250499</td>\n",
       "      <td>-0.381507</td>\n",
       "      <td>-2.481059</td>\n",
       "      <td>-2.791023</td>\n",
       "      <td>-2.244865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>F:/audio_speech_actors_01-24/Actor_01/03-01-01...</td>\n",
       "      <td>-695.557861</td>\n",
       "      <td>59.240154</td>\n",
       "      <td>-5.372777</td>\n",
       "      <td>19.776367</td>\n",
       "      <td>5.200387</td>\n",
       "      <td>3.324630</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.055913</td>\n",
       "      <td>-3.102514</td>\n",
       "      <td>-1.697880</td>\n",
       "      <td>-2.922661</td>\n",
       "      <td>-2.544465</td>\n",
       "      <td>-1.289832</td>\n",
       "      <td>-0.797254</td>\n",
       "      <td>-3.586074</td>\n",
       "      <td>-2.706395</td>\n",
       "      <td>-2.812933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>F:/audio_speech_actors_01-24/Actor_01/03-01-01...</td>\n",
       "      <td>-694.004333</td>\n",
       "      <td>61.496510</td>\n",
       "      <td>-3.262743</td>\n",
       "      <td>16.971298</td>\n",
       "      <td>2.142968</td>\n",
       "      <td>4.266798</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.382858</td>\n",
       "      <td>-2.590943</td>\n",
       "      <td>-1.929074</td>\n",
       "      <td>-2.390322</td>\n",
       "      <td>-2.269381</td>\n",
       "      <td>-2.486079</td>\n",
       "      <td>-0.589257</td>\n",
       "      <td>-3.248326</td>\n",
       "      <td>-2.979813</td>\n",
       "      <td>-2.769281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>F:/audio_speech_actors_01-24/Actor_01/03-01-01...</td>\n",
       "      <td>-687.513367</td>\n",
       "      <td>59.441540</td>\n",
       "      <td>-0.703714</td>\n",
       "      <td>16.645708</td>\n",
       "      <td>3.730826</td>\n",
       "      <td>6.181194</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.024173</td>\n",
       "      <td>-2.586190</td>\n",
       "      <td>-2.420421</td>\n",
       "      <td>-3.243219</td>\n",
       "      <td>-2.762588</td>\n",
       "      <td>-1.960003</td>\n",
       "      <td>-0.453890</td>\n",
       "      <td>-2.976706</td>\n",
       "      <td>-2.914763</td>\n",
       "      <td>-3.909605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>calm</td>\n",
       "      <td>1</td>\n",
       "      <td>F:/audio_speech_actors_01-24/Actor_01/03-01-02...</td>\n",
       "      <td>-729.980164</td>\n",
       "      <td>66.515892</td>\n",
       "      <td>-0.941984</td>\n",
       "      <td>19.070974</td>\n",
       "      <td>4.297080</td>\n",
       "      <td>5.635082</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.519869</td>\n",
       "      <td>-1.797158</td>\n",
       "      <td>-1.296814</td>\n",
       "      <td>-3.051891</td>\n",
       "      <td>-1.131349</td>\n",
       "      <td>-1.063672</td>\n",
       "      <td>-1.141021</td>\n",
       "      <td>-2.373389</td>\n",
       "      <td>-3.204345</td>\n",
       "      <td>-3.363193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender  emotion  actor                                               path  \\\n",
       "0   male  neutral      1  F:/audio_speech_actors_01-24/Actor_01/03-01-01...   \n",
       "1   male  neutral      1  F:/audio_speech_actors_01-24/Actor_01/03-01-01...   \n",
       "2   male  neutral      1  F:/audio_speech_actors_01-24/Actor_01/03-01-01...   \n",
       "3   male  neutral      1  F:/audio_speech_actors_01-24/Actor_01/03-01-01...   \n",
       "4   male     calm      1  F:/audio_speech_actors_01-24/Actor_01/03-01-02...   \n",
       "\n",
       "            0          1         2          3         4         5  ...  \\\n",
       "0 -700.398926  58.630211 -3.025852  16.040241  4.248529  3.869935  ...   \n",
       "1 -695.557861  59.240154 -5.372777  19.776367  5.200387  3.324630  ...   \n",
       "2 -694.004333  61.496510 -3.262743  16.971298  2.142968  4.266798  ...   \n",
       "3 -687.513367  59.441540 -0.703714  16.645708  3.730826  6.181194  ...   \n",
       "4 -729.980164  66.515892 -0.941984  19.070974  4.297080  5.635082  ...   \n",
       "\n",
       "         30        31        32        33        34        35        36  \\\n",
       "0 -1.411359 -2.769772 -2.042009 -2.522663 -2.507448 -2.250499 -0.381507   \n",
       "1 -1.055913 -3.102514 -1.697880 -2.922661 -2.544465 -1.289832 -0.797254   \n",
       "2 -1.382858 -2.590943 -1.929074 -2.390322 -2.269381 -2.486079 -0.589257   \n",
       "3 -2.024173 -2.586190 -2.420421 -3.243219 -2.762588 -1.960003 -0.453890   \n",
       "4 -1.519869 -1.797158 -1.296814 -3.051891 -1.131349 -1.063672 -1.141021   \n",
       "\n",
       "         37        38        39  \n",
       "0 -2.481059 -2.791023 -2.244865  \n",
       "1 -3.586074 -2.706395 -2.812933  \n",
       "2 -3.248326 -2.979813 -2.769281  \n",
       "3 -2.976706 -2.914763 -3.909605  \n",
       "4 -2.373389 -3.204345 -3.363193  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.fillna(0)\n",
    "\n",
    "print(df.shape)\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['path','emotion','gender','actor'],axis=1)\n",
    "                                                    , df['emotion']\n",
    "                                                    , test_size=0.25\n",
    "                                                    , shuffle=True\n",
    "                                                    , random_state=42\n",
    "                                                   )\n",
    "\n",
    "# Lets see how the data present itself before normalisation \n",
    "X_train[150:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std\n",
    "\n",
    "# Check the dataset now \n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# one hot encode the target \n",
    "lb = LabelEncoder()\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(lb.classes_)\n",
    "#print(y_train[0:10])\n",
    "#print(y_test[0:10])\n",
    "\n",
    "# Pickel the lb object for future use \n",
    "filename = 'labels'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(lb,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(16, 5, padding='same',input_shape=(X_train.shape[1],1)))  # X_train.shape[1] = No. of Columns\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=(5)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(32, 5, padding='same',input_shape=(X_train.shape[1],1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8)) # Target class number\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(16, 5, padding='same',input_shape=(X_train.shape[1],1)))  # X_train.shape[1] = No. of Columns\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=(5)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(32, 5, padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=(5)))\n",
    "model.add(Conv1D(64, 5, padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "#model.add(Conv1D(64, 5, padding='same'))\n",
    "model.add(Dense(8)) # Target class number\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "#opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(32, 5, padding='same',input_shape=(X_train.shape[1],1)))  # X_train.shape[1] = No. of Columns\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=(5)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(64, 5, padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=(5)))\n",
    "model.add(Conv1D(64, 5, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8)) # Target class number\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='RMSprop',metrics=['accuracy'])\n",
    "model_history=model.fit(X_train, y_train, batch_size=16, epochs=40, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.plot(model_history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss of the model is - \" , model.evaluate(X_test,y_test)[0])\n",
    "print(\"Accuracy of the model is - \" , model.evaluate(X_test,y_test)[1]*100 , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTIONS\n",
    "pred = model.predict(X_test)\n",
    "pred=pred.argmax(axis=1)\n",
    "pred = pred.astype(int).flatten()\n",
    "pred = (lb.inverse_transform((pred)))\n",
    "pred = pd.DataFrame({'Predicted Values': pred})\n",
    "\n",
    "# ACTUAL LABELS\n",
    "y=y_test.argmax(axis=1)\n",
    "y = y.astype(int).flatten()\n",
    "y= (lb.inverse_transform((y)))\n",
    "y = pd.DataFrame({'Actual Values': y})\n",
    "\n",
    "# COMBINE BOTH \n",
    "finaldf = y.join(pred)\n",
    "finaldf[140:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, pred, target_names = ['angry','calm','disgust','fear','happy','neutral','sad','surprise']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y, pred)\n",
    "plt.figure(figsize = (12, 10))\n",
    "cm = pd.DataFrame(cm , index = [i for i in lb.classes_] , columns = [i for i in lb.classes_])\n",
    "ax = sns.heatmap(cm, linecolor='white', cmap='Purples', linewidth=1, annot=True, fmt='')\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.title('Confusion Matrix', size=20)\n",
    "plt.xlabel('Predicted Labels', size=14)\n",
    "plt.ylabel('Actual Labels', size=14)\n",
    "plt.savefig('Initial_Model_Confusion_Matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and weights\n",
    "model_name = 'Audio_Emotion_Model.h5'\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Save model and weights at %s ' % model_path)\n",
    "\n",
    "# Save the model to disk\n",
    "model_json = model.to_json()\n",
    "with open(\"model_json.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('model_json.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"saved_models/Audio_Emotion_Model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# Keras optimiser\n",
    "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
